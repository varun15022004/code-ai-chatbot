{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Furniture Dataset - Exploratory Data Analysis (EDA)\n",
    "\n",
    "This notebook explores and analyzes the furniture dataset to understand:\n",
    "- Dataset structure and quality\n",
    "- Missing values and data cleaning requirements\n",
    "- Category distributions for furniture types\n",
    "- Price analysis and patterns\n",
    "- Material, color, and brand insights\n",
    "- Image URL availability and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import re\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/intern_data_ikarus.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\nFirst 3 rows:\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Missing Values:\")\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing_data,\n",
    "    'Missing_Percentage': missing_percent\n",
    "})\n",
    "print(missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Percentage', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to safely parse string representations of lists\n",
    "def safe_parse_list(val):\n",
    "    if pd.isna(val) or val == '':\n",
    "        return []\n",
    "    try:\n",
    "        if isinstance(val, str):\n",
    "            # Clean and parse the string\n",
    "            val = val.strip()\n",
    "            if val.startswith('[') and val.endswith(']'):\n",
    "                return ast.literal_eval(val)\n",
    "            else:\n",
    "                # Handle comma-separated values\n",
    "                return [item.strip().strip('\"').strip(\"'\") for item in val.split(',')]\n",
    "        return val\n",
    "    except:\n",
    "        return [str(val)]  # Return as single-item list if parsing fails\n",
    "\n",
    "# Function to clean price data\n",
    "def clean_price(price_str):\n",
    "    if pd.isna(price_str) or price_str == '':\n",
    "        return np.nan\n",
    "    try:\n",
    "        # Remove $ sign and commas, convert to float\n",
    "        price_cleaned = re.sub(r'[^\\d.]', '', str(price_str))\n",
    "        return float(price_cleaned) if price_cleaned else np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Clean price column\n",
    "df_clean['price_numeric'] = df_clean['price'].apply(clean_price)\n",
    "\n",
    "# Parse categories and images as lists\n",
    "df_clean['categories_list'] = df_clean['categories'].apply(safe_parse_list)\n",
    "df_clean['images_list'] = df_clean['images'].apply(safe_parse_list)\n",
    "\n",
    "# Clean text columns\n",
    "text_columns = ['title', 'brand', 'description', 'material', 'color']\n",
    "for col in text_columns:\n",
    "    df_clean[col] = df_clean[col].astype(str).str.strip()\n",
    "    df_clean[col] = df_clean[col].replace(['nan', 'None', ''], np.nan)\n",
    "\n",
    "print(f\"Cleaned dataset shape: {df_clean.shape}\")\n",
    "print(f\"Valid prices: {df_clean['price_numeric'].notna().sum()} / {len(df_clean)}\")\n",
    "print(f\"Products with categories: {df_clean['categories_list'].apply(lambda x: len(x) > 0).sum()}\")\n",
    "print(f\"Products with images: {df_clean['images_list'].apply(lambda x: len(x) > 0).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Price Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price statistics\n",
    "price_stats = df_clean['price_numeric'].describe()\n",
    "print(\"Price Statistics:\")\n",
    "print(price_stats)\n",
    "\n",
    "# Create price visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Furniture Price Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Histogram of prices\n",
    "axes[0, 0].hist(df_clean['price_numeric'].dropna(), bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('Price Distribution')\n",
    "axes[0, 0].set_xlabel('Price ($)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Box plot of prices\n",
    "axes[0, 1].boxplot(df_clean['price_numeric'].dropna(), vert=True)\n",
    "axes[0, 1].set_title('Price Box Plot')\n",
    "axes[0, 1].set_ylabel('Price ($)')\n",
    "\n",
    "# Log scale histogram (for better visualization if prices vary widely)\n",
    "valid_prices = df_clean['price_numeric'].dropna()\n",
    "valid_prices = valid_prices[valid_prices > 0]\n",
    "axes[1, 0].hist(np.log10(valid_prices), bins=20, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[1, 0].set_title('Price Distribution (Log Scale)')\n",
    "axes[1, 0].set_xlabel('Log10(Price)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Price ranges\n",
    "price_ranges = pd.cut(df_clean['price_numeric'], \n",
    "                     bins=[0, 25, 50, 100, 200, 500, float('inf')], \n",
    "                     labels=['$0-25', '$25-50', '$50-100', '$100-200', '$200-500', '$500+'])\n",
    "price_range_counts = price_ranges.value_counts().sort_index()\n",
    "\n",
    "axes[1, 1].bar(range(len(price_range_counts)), price_range_counts.values, color='coral')\n",
    "axes[1, 1].set_title('Products by Price Range')\n",
    "axes[1, 1].set_xlabel('Price Range')\n",
    "axes[1, 1].set_ylabel('Number of Products')\n",
    "axes[1, 1].set_xticks(range(len(price_range_counts)))\n",
    "axes[1, 1].set_xticklabels(price_range_counts.index, rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Price range distribution table\n",
    "print(\"\\nPrice Range Distribution:\")\n",
    "for range_label, count in price_range_counts.items():\n",
    "    percentage = (count / len(df_clean)) * 100\n",
    "    print(f\"{range_label}: {count} products ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Category Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten all categories\n",
    "all_categories = []\n",
    "for cat_list in df_clean['categories_list']:\n",
    "    if isinstance(cat_list, list):\n",
    "        all_categories.extend([cat.strip() for cat in cat_list if cat.strip()])\n",
    "\n",
    "category_counts = Counter(all_categories)\n",
    "top_categories = dict(category_counts.most_common(20))\n",
    "\n",
    "print(f\"Total unique categories: {len(category_counts)}\")\n",
    "print(f\"Top 20 categories:\")\n",
    "for category, count in top_categories.items():\n",
    "    percentage = (count / len(df_clean)) * 100\n",
    "    print(f\"{category}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# Visualize top categories\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 12))\n",
    "fig.suptitle('Furniture Category Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Top categories bar chart\n",
    "categories = list(top_categories.keys())[:15]\n",
    "counts = list(top_categories.values())[:15]\n",
    "\n",
    "axes[0].barh(range(len(categories)), counts, color='lightblue')\n",
    "axes[0].set_title('Top 15 Furniture Categories')\n",
    "axes[0].set_xlabel('Number of Products')\n",
    "axes[0].set_yticks(range(len(categories)))\n",
    "axes[0].set_yticklabels([cat[:30] + '...' if len(cat) > 30 else cat for cat in categories])\n",
    "\n",
    "# Furniture-specific categories (filter for main furniture types)\n",
    "furniture_keywords = ['chairs', 'tables', 'furniture', 'storage', 'bedroom', 'living room', \n",
    "                     'dining', 'office', 'ottomans', 'barstools', 'nightstands', 'bookcases']\n",
    "\n",
    "furniture_categories = {}\n",
    "for category, count in category_counts.items():\n",
    "    category_lower = category.lower()\n",
    "    if any(keyword in category_lower for keyword in furniture_keywords):\n",
    "        furniture_categories[category] = count\n",
    "\n",
    "# Sort and get top furniture categories\n",
    "top_furniture = dict(sorted(furniture_categories.items(), key=lambda x: x[1], reverse=True)[:12])\n",
    "\n",
    "if top_furniture:\n",
    "    furn_cats = list(top_furniture.keys())\n",
    "    furn_counts = list(top_furniture.values())\n",
    "    \n",
    "    axes[1].pie(furn_counts, labels=[cat[:20] + '...' if len(cat) > 20 else cat for cat in furn_cats], \n",
    "                autopct='%1.1f%%', startangle=90)\n",
    "    axes[1].set_title('Main Furniture Categories Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Brand and Manufacturer Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brand analysis\n",
    "brand_counts = df_clean['brand'].value_counts().head(15)\n",
    "manufacturer_counts = df_clean['manufacturer'].value_counts().head(15)\n",
    "\n",
    "print(\"Top 15 Brands:\")\n",
    "for brand, count in brand_counts.items():\n",
    "    percentage = (count / len(df_clean)) * 100\n",
    "    print(f\"{brand}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\nTop 15 Manufacturers:\")\n",
    "for manufacturer, count in manufacturer_counts.items():\n",
    "    if pd.notna(manufacturer) and manufacturer != 'nan':\n",
    "        percentage = (count / len(df_clean)) * 100\n",
    "        print(f\"{manufacturer}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# Visualize brands and manufacturers\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "fig.suptitle('Brand and Manufacturer Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Top brands\n",
    "axes[0].barh(range(len(brand_counts)), brand_counts.values, color='lightcoral')\n",
    "axes[0].set_title('Top 15 Brands')\n",
    "axes[0].set_xlabel('Number of Products')\n",
    "axes[0].set_yticks(range(len(brand_counts)))\n",
    "axes[0].set_yticklabels(brand_counts.index)\n",
    "\n",
    "# Top manufacturers (excluding NaN)\n",
    "valid_manufacturers = manufacturer_counts.dropna()\n",
    "valid_manufacturers = valid_manufacturers[valid_manufacturers.index != 'nan']\n",
    "if len(valid_manufacturers) > 0:\n",
    "    axes[1].barh(range(len(valid_manufacturers)), valid_manufacturers.values, color='lightgreen')\n",
    "    axes[1].set_title('Top Manufacturers')\n",
    "    axes[1].set_xlabel('Number of Products')\n",
    "    axes[1].set_yticks(range(len(valid_manufacturers)))\n",
    "    axes[1].set_yticklabels(valid_manufacturers.index)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Material and Color Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Material analysis\n",
    "material_counts = df_clean['material'].value_counts().head(15)\n",
    "color_counts = df_clean['color'].value_counts().head(15)\n",
    "\n",
    "print(\"Top 15 Materials:\")\n",
    "for material, count in material_counts.items():\n",
    "    if pd.notna(material) and material != 'nan':\n",
    "        percentage = (count / len(df_clean)) * 100\n",
    "        print(f\"{material}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\nTop 15 Colors:\")\n",
    "for color, count in color_counts.items():\n",
    "    if pd.notna(color) and color != 'nan':\n",
    "        percentage = (count / len(df_clean)) * 100\n",
    "        print(f\"{color}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# Visualize materials and colors\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Material and Color Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Materials bar chart\n",
    "valid_materials = material_counts.dropna()\n",
    "valid_materials = valid_materials[valid_materials.index != 'nan'][:10]\n",
    "if len(valid_materials) > 0:\n",
    "    axes[0, 0].bar(range(len(valid_materials)), valid_materials.values, color='gold')\n",
    "    axes[0, 0].set_title('Top 10 Materials')\n",
    "    axes[0, 0].set_xlabel('Material')\n",
    "    axes[0, 0].set_ylabel('Number of Products')\n",
    "    axes[0, 0].set_xticks(range(len(valid_materials)))\n",
    "    axes[0, 0].set_xticklabels(valid_materials.index, rotation=45, ha='right')\n",
    "\n",
    "# Colors bar chart\n",
    "valid_colors = color_counts.dropna()\n",
    "valid_colors = valid_colors[valid_colors.index != 'nan'][:10]\n",
    "if len(valid_colors) > 0:\n",
    "    axes[0, 1].bar(range(len(valid_colors)), valid_colors.values, color='lightblue')\n",
    "    axes[0, 1].set_title('Top 10 Colors')\n",
    "    axes[0, 1].set_xlabel('Color')\n",
    "    axes[0, 1].set_ylabel('Number of Products')\n",
    "    axes[0, 1].set_xticks(range(len(valid_colors)))\n",
    "    axes[0, 1].set_xticklabels(valid_colors.index, rotation=45, ha='right')\n",
    "\n",
    "# Material pie chart\n",
    "if len(valid_materials) > 0:\n",
    "    axes[1, 0].pie(valid_materials.values, labels=valid_materials.index, autopct='%1.1f%%', startangle=90)\n",
    "    axes[1, 0].set_title('Material Distribution')\n",
    "\n",
    "# Color pie chart\n",
    "if len(valid_colors) > 0:\n",
    "    axes[1, 1].pie(valid_colors.values, labels=valid_colors.index, autopct='%1.1f%%', startangle=90)\n",
    "    axes[1, 1].set_title('Color Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Geographic and Dimensional Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country of origin analysis\n",
    "country_counts = df_clean['country_of_origin'].value_counts().head(10)\n",
    "\n",
    "print(\"Top 10 Countries of Origin:\")\n",
    "for country, count in country_counts.items():\n",
    "    if pd.notna(country) and country != 'nan':\n",
    "        percentage = (count / len(df_clean)) * 100\n",
    "        print(f\"{country}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# Package dimensions analysis\n",
    "print(f\"\\nProducts with package dimensions: {df_clean['package_dimensions'].notna().sum()} / {len(df_clean)}\")\n",
    "print(f\"Percentage with dimensions: {(df_clean['package_dimensions'].notna().sum() / len(df_clean)) * 100:.1f}%\")\n",
    "\n",
    "# Visualize country distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "fig.suptitle('Geographic and Dimensional Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Country of origin\n",
    "valid_countries = country_counts.dropna()\n",
    "valid_countries = valid_countries[valid_countries.index != 'nan']\n",
    "if len(valid_countries) > 0:\n",
    "    axes[0].pie(valid_countries.values, labels=valid_countries.index, autopct='%1.1f%%', startangle=90)\n",
    "    axes[0].set_title('Products by Country of Origin')\n",
    "\n",
    "# Data completeness by field\n",
    "completeness_data = {\n",
    "    'Title': df_clean['title'].notna().sum(),\n",
    "    'Price': df_clean['price_numeric'].notna().sum(),\n",
    "    'Category': df_clean['categories_list'].apply(lambda x: len(x) > 0).sum(),\n",
    "    'Images': df_clean['images_list'].apply(lambda x: len(x) > 0).sum(),\n",
    "    'Brand': df_clean['brand'].notna().sum(),\n",
    "    'Material': (df_clean['material'].notna() & (df_clean['material'] != 'nan')).sum(),\n",
    "    'Color': (df_clean['color'].notna() & (df_clean['color'] != 'nan')).sum(),\n",
    "    'Description': df_clean['description'].notna().sum()\n",
    "}\n",
    "\n",
    "fields = list(completeness_data.keys())\n",
    "percentages = [(count / len(df_clean)) * 100 for count in completeness_data.values()]\n",
    "\n",
    "axes[1].bar(fields, percentages, color='skyblue')\n",
    "axes[1].set_title('Data Completeness by Field')\n",
    "axes[1].set_xlabel('Fields')\n",
    "axes[1].set_ylabel('Completeness (%)')\n",
    "axes[1].set_xticklabels(fields, rotation=45, ha='right')\n",
    "axes[1].set_ylim(0, 100)\n",
    "\n",
    "# Add percentage labels on bars\n",
    "for i, v in enumerate(percentages):\n",
    "    axes[1].text(i, v + 1, f'{v:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Image URL Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze image URLs\n",
    "image_stats = {\n",
    "    'products_with_images': 0,\n",
    "    'total_images': 0,\n",
    "    'avg_images_per_product': 0,\n",
    "    'amazon_urls': 0,\n",
    "    'valid_urls': 0\n",
    "}\n",
    "\n",
    "all_images = []\n",
    "products_with_images = 0\n",
    "amazon_url_count = 0\n",
    "\n",
    "for images in df_clean['images_list']:\n",
    "    if isinstance(images, list) and len(images) > 0:\n",
    "        # Filter out empty strings\n",
    "        valid_images = [img.strip() for img in images if img.strip()]\n",
    "        if valid_images:\n",
    "            products_with_images += 1\n",
    "            all_images.extend(valid_images)\n",
    "            \n",
    "            # Count Amazon URLs\n",
    "            amazon_urls = [img for img in valid_images if 'amazon' in img.lower()]\n",
    "            amazon_url_count += len(amazon_urls)\n",
    "\n",
    "image_stats['products_with_images'] = products_with_images\n",
    "image_stats['total_images'] = len(all_images)\n",
    "image_stats['avg_images_per_product'] = len(all_images) / products_with_images if products_with_images > 0 else 0\n",
    "image_stats['amazon_urls'] = amazon_url_count\n",
    "image_stats['valid_urls'] = len([img for img in all_images if img.startswith('http')])\n",
    "\n",
    "print(\"Image URL Statistics:\")\n",
    "print(f\"Products with images: {image_stats['products_with_images']} / {len(df_clean)} ({(image_stats['products_with_images']/len(df_clean))*100:.1f}%)\")\n",
    "print(f\"Total image URLs: {image_stats['total_images']}\")\n",
    "print(f\"Average images per product: {image_stats['avg_images_per_product']:.1f}\")\n",
    "print(f\"Amazon URLs: {image_stats['amazon_urls']} ({(image_stats['amazon_urls']/image_stats['total_images'])*100:.1f}%)\")\n",
    "print(f\"Valid HTTP URLs: {image_stats['valid_urls']} ({(image_stats['valid_urls']/image_stats['total_images'])*100:.1f}%)\")\n",
    "\n",
    "# Sample image URLs\n",
    "print(\"\\nSample image URLs:\")\n",
    "sample_images = all_images[:5] if all_images else []\n",
    "for i, img in enumerate(sample_images, 1):\n",
    "    print(f\"{i}. {img[:100]}...\" if len(img) > 100 else f\"{i}. {img}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Text Analysis for AI Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text length analysis for title and description\n",
    "df_clean['title_length'] = df_clean['title'].astype(str).str.len()\n",
    "df_clean['description_length'] = df_clean['description'].astype(str).str.len()\n",
    "\n",
    "# Word count analysis\n",
    "df_clean['title_word_count'] = df_clean['title'].astype(str).str.split().str.len()\n",
    "df_clean['description_word_count'] = df_clean['description'].astype(str).str.split().str.len()\n",
    "\n",
    "text_stats = {\n",
    "    'avg_title_length': df_clean['title_length'].mean(),\n",
    "    'avg_description_length': df_clean['description_length'].mean(),\n",
    "    'avg_title_words': df_clean['title_word_count'].mean(),\n",
    "    'avg_description_words': df_clean['description_word_count'].mean()\n",
    "}\n",
    "\n",
    "print(\"Text Statistics for AI Model Training:\")\n",
    "print(f\"Average title length: {text_stats['avg_title_length']:.1f} characters\")\n",
    "print(f\"Average description length: {text_stats['avg_description_length']:.1f} characters\")\n",
    "print(f\"Average title word count: {text_stats['avg_title_words']:.1f} words\")\n",
    "print(f\"Average description word count: {text_stats['avg_description_words']:.1f} words\")\n",
    "\n",
    "# Create combined text for embeddings\n",
    "def create_combined_text(row):\n",
    "    \"\"\"Combine title, description, categories, material, and color for embeddings\"\"\"\n",
    "    text_parts = []\n",
    "    \n",
    "    if pd.notna(row['title']) and row['title'] != 'nan':\n",
    "        text_parts.append(str(row['title']))\n",
    "    \n",
    "    if pd.notna(row['description']) and row['description'] != 'nan':\n",
    "        text_parts.append(str(row['description']))\n",
    "    \n",
    "    if isinstance(row['categories_list'], list) and len(row['categories_list']) > 0:\n",
    "        text_parts.append(' '.join(row['categories_list']))\n",
    "    \n",
    "    if pd.notna(row['material']) and row['material'] != 'nan':\n",
    "        text_parts.append(f\"material: {row['material']}\")\n",
    "    \n",
    "    if pd.notna(row['color']) and row['color'] != 'nan':\n",
    "        text_parts.append(f\"color: {row['color']}\")\n",
    "    \n",
    "    return ' '.join(text_parts)\n",
    "\n",
    "df_clean['combined_text'] = df_clean.apply(create_combined_text, axis=1)\n",
    "\n",
    "print(f\"\\nAverage combined text length: {df_clean['combined_text'].str.len().mean():.1f} characters\")\n",
    "print(f\"Average combined text word count: {df_clean['combined_text'].str.split().str.len().mean():.1f} words\")\n",
    "\n",
    "# Sample combined texts\n",
    "print(\"\\nSample combined texts for embedding:\")\n",
    "for i in range(3):\n",
    "    sample_text = df_clean['combined_text'].iloc[i]\n",
    "    print(f\"\\n{i+1}. {sample_text[:200]}...\" if len(sample_text) > 200 else f\"\\n{i+1}. {sample_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Data Quality Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive data quality report\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA QUALITY SUMMARY & RECOMMENDATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n📊 DATASET OVERVIEW:\")\n",
    "print(f\"• Total products: {len(df_clean)}\")\n",
    "print(f\"• Unique product IDs: {df_clean['uniq_id'].nunique()}\")\n",
    "print(f\"• Duplicate products: {len(df_clean) - df_clean['uniq_id'].nunique()}\")\n",
    "\n",
    "print(f\"\\n💰 PRICING DATA:\")\n",
    "valid_prices = df_clean['price_numeric'].notna().sum()\n",
    "print(f\"• Products with valid prices: {valid_prices} / {len(df_clean)} ({(valid_prices/len(df_clean))*100:.1f}%)\")\n",
    "if valid_prices > 0:\n",
    "    print(f\"• Price range: ${df_clean['price_numeric'].min():.2f} - ${df_clean['price_numeric'].max():.2f}\")\n",
    "    print(f\"• Median price: ${df_clean['price_numeric'].median():.2f}\")\n",
    "\n",
    "print(f\"\\n🏷️ CATEGORY DATA:\")\n",
    "products_with_cats = df_clean['categories_list'].apply(lambda x: len(x) > 0).sum()\n",
    "print(f\"• Products with categories: {products_with_cats} / {len(df_clean)} ({(products_with_cats/len(df_clean))*100:.1f}%)\")\n",
    "print(f\"• Total unique categories: {len(category_counts)}\")\n",
    "print(f\"• Most common category: {list(category_counts.keys())[0]} ({list(category_counts.values())[0]} products)\")\n",
    "\n",
    "print(f\"\\n🖼️ IMAGE DATA:\")\n",
    "print(f\"• Products with images: {image_stats['products_with_images']} / {len(df_clean)} ({(image_stats['products_with_images']/len(df_clean))*100:.1f}%)\")\n",
    "print(f\"• Total image URLs: {image_stats['total_images']}\")\n",
    "print(f\"• Average images per product: {image_stats['avg_images_per_product']:.1f}\")\n",
    "\n",
    "print(f\"\\n📝 TEXT DATA:\")\n",
    "titles_available = (df_clean['title'].notna() & (df_clean['title'] != 'nan')).sum()\n",
    "descriptions_available = (df_clean['description'].notna() & (df_clean['description'] != 'nan')).sum()\n",
    "print(f\"• Products with titles: {titles_available} / {len(df_clean)} ({(titles_available/len(df_clean))*100:.1f}%)\")\n",
    "print(f\"• Products with descriptions: {descriptions_available} / {len(df_clean)} ({(descriptions_available/len(df_clean))*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n🔧 DATA CLEANING RECOMMENDATIONS:\")\n",
    "print(f\"• ✅ Price cleaning: Remove $ symbols, convert to numeric\")\n",
    "print(f\"• ✅ Category parsing: Convert string representations to lists\")\n",
    "print(f\"• ✅ Image URL validation: Check for valid HTTP URLs\")\n",
    "print(f\"• ✅ Text normalization: Clean and standardize text fields\")\n",
    "print(f\"• ✅ Missing value imputation: Use category medians for prices\")\n",
    "print(f\"• ✅ Duplicate removal: Based on unique_id field\")\n",
    "\n",
    "print(f\"\\n🤖 AI MODEL READINESS:\")\n",
    "print(f\"• ✅ Text embedding: {len(df_clean)} products have combined text\")\n",
    "print(f\"• ✅ Image processing: {image_stats['products_with_images']} products have images\")\n",
    "print(f\"• ✅ Category classification: {len(category_counts)} unique categories\")\n",
    "print(f\"• ✅ Price prediction: {valid_prices} products with pricing data\")\n",
    "\n",
    "print(f\"\\n💡 BUSINESS INSIGHTS:\")\n",
    "if valid_countries := country_counts.dropna():\n",
    "    top_country = valid_countries.index[0]\n",
    "    print(f\"• Most products manufactured in: {top_country}\")\n",
    "if valid_materials := material_counts.dropna():\n",
    "    top_material = valid_materials.index[0]\n",
    "    print(f\"• Most common material: {top_material}\")\n",
    "if valid_colors := color_counts.dropna():\n",
    "    top_color = valid_colors.index[0]\n",
    "    print(f\"• Most popular color: {top_color}\")\n",
    "print(f\"• Price range diversity: {len(price_range_counts)} price segments\")\n",
    "\n",
    "# Save cleaned dataset\n",
    "df_clean.to_csv('../data/cleaned_furniture_data.csv', index=False)\n",
    "print(f\"\\n💾 Cleaned dataset saved as: cleaned_furniture_data.csv\")\n",
    "print(f\"Ready for AI model training and application development!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}